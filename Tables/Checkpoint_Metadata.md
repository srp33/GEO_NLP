Model                                                            Embedding size  Data source type   Model category                                                   Fine tuning                                                                                                                                                                                                
--------------------------------------------------------------  ---------------  -----------------  ---------------------------------------------------------------  -----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
FremyCompany/BioLORD-2023                                                   768  Biomedical         Ontology-driven concept representations                          This model is based on sentence-transformers/all-mpnet-base-v2 and was further fine tuned on the BioLORD-Dataset and LLM-generated definitions from the Automatic Glossary of Clinical Terminology (AGCT). 
NeuML/pubmedbert-base-embeddings                                            768  Biomedical         Bidirectional Encoder Representations from Transformers (BERT)                                                                                                                                                                                                              
albert/albert-base-v2                                                       768  General            Masked language modeling (MLM)                                                                                                                                                                                                                                              
albert/albert-xxlarge-v2                                                   4096  General            Masked language modeling (MLM)                                   This checkpoint ostensibly is a fine-tuning of albert/albert-xxlarge-v2.                                                                                                                                   
allenai/biomed_roberta_base                                                 768  Biomedical         Bidirectional Encoder Representations from Transformers (BERT)                                                                                                                                                                                                              
allenai/scibert_scivocab_uncased                                            768  Scientific         Bidirectional Encoder Representations from Transformers (BERT)                                                                                                                                                                                                              
emilyalsentzer/Bio_ClinicalBERT                                             768  Biomedical         Bidirectional Encoder Representations from Transformers (BERT)                                                                                                                                                                                                              
fasttext/cbow-commoncrawl                                                   300  General            Continuous Bag of Words (Word2Vec)                                                                                                                                                                                                                                          
fasttext/cbow-wikinews                                                      300  General            Continuous Bag of Words (Word2Vec)                                                                                                                                                                                                                                          
hkunlp/instructor-xl                                                        768  General            Instruction-fine-tuned text embedding model                                                                                                                                                                                                                                 
medicalai/ClinicalBERT                                                      768  Biomedical         Bidirectional Encoder Representations from Transformers (BERT)                                                                                                                                                                                                              
microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract-fulltext               768  Biomedical         Bidirectional Encoder Representations from Transformers (BERT)                                                                                                                                                                                                              
nomic-ai/nomic-embed-text-v1.5                                              768  General            Matryoshka Representation Learning                                                                                                                                                                                                                                          
nuvocare/WikiMedical_sent_biobert                                           768  Biomedical         Bidirectional Encoder Representations from Transformers (BERT)   Based on the dmis-lab/biobert-base-cased-v1.2 backbone and has been trained on the WikiMedical_sentence_simialrity dataset.                                                                                
openai/text-embedding-3-large                                              3072  General            Generative Pre-trained Transformer (GPT)                                                                                                                                                                                                                                    
openai/text-embedding-3-small                                              1536  General            Generative Pre-trained Transformer (GPT)                                                                                                                                                                                                                                    
openai/text-embedding-ada-002                                              1536  General            Generative Pre-trained Transformer (GPT)                                                                                                                                                                                                                                    
pritamdeka/S-BioBert-snli-multinli-stsb                                     768  Biomedical         Bidirectional Encoder Representations from Transformers (BERT)                                                                                                                                                                                                              
pritamdeka/S-Biomed-Roberta-snli-multinli-stsb                              768  Biomedical         Bidirectional Encoder Representations from Transformers (BERT)   The base model used is allenai/biomed_roberta_base which has been fine-tuned for sentence similarity.                                                                                                      
pritamdeka/S-PubMedBert-MS-MARCO-SCIFACT                                    768  Biomedical         Bidirectional Encoder Representations from Transformers (BERT)                                                                                                                                                                                                              
sentence-transformers/all-MiniLM-L6-v2                                      384  General            Self-supervised contrastive learning                             We used the pretrained nreimers/MiniLM-L6-H384-uncased model and fine-tuned in on a 1B sentence pairs dataset.                                                                                             
sentence-transformers/all-mpnet-base-v2                                     768  General            Self-supervised contrastive learning                             We used the pretrained microsoft/mpnet-base model and fine-tuned in on a 1B sentence pairs dataset.                                                                                                        
sentence-transformers/all-roberta-large-v1                                 1024  General            Self-supervised contrastive learning                             We used the pretrained roberta-large model and fine-tuned in on a 1B sentence pairs dataset.                                                                                                               
sentence-transformers/average_word_embeddings_glove.6B.300d                 300  General            Global Vectors for Word Representation (GloVe)                                                                                                                                                                                                                              
sentence-transformers/average_word_embeddings_glove.840B.300d               300  General            Global Vectors for Word Representation (GloVe)                                                                                                                                                                                                                              
sentence-transformers/msmarco-distilbert-base-v3                            768  General            Bidirectional Encoder Representations from Transformers (BERT)                                                                                                                                                                                                              
sentence-transformers/paraphrase-TinyBERT-L6-v2                             768  General            Bidirectional Encoder Representations from Transformers (BERT)                                                                                                                                                                                                              
sentence-transformers/sentence-t5-large                                     768  General            Text-to-text transformers (T5)                                                                                                                                                                                                                                              
sentence-transformers/sentence-t5-xl                                        768  General            Text-to-text transformers (T5)                                                                                                                                                                                                                                              
thenlper/gte-large                                                         1024  General            Multi-stage contrastive learning                                                                                                                                                                                                                                            
