Method                                                          Correlation coefficient 
--------------------------------------------------------------  ------------------------
albert/albert-base-v2                                           0.600                   
albert/albert-xxlarge-v2                                        0.543                   
allenai/biomed_roberta_base                                     0.829                   
allenai/scibert_scivocab_uncased                                0.486                   
bm25                                                            0.143                   
bm25plus                                                        0.429                   
emilyalsentzer/Bio_ClinicalBERT                                 0.943                   
fasttext/cbow-commoncrawl                                       0.714                   
fasttext/cbow-wikinews                                          0.886                   
FremyCompany/BioLORD-2023                                       -0.029                  
hkunlp/instructor-xl                                            0.257                   
medicalai/ClinicalBERT                                          0.486                   
microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract-fulltext   0.371                   
NeuML/pubmedbert-base-embeddings                                0.086                   
nomic-ai/nomic-embed-text-v1.5                                  -0.029                  
nuvocare/WikiMedical_sent_biobert                               0.257                   
openai/text-embedding-3-large                                   0.257                   
openai/text-embedding-3-small                                   0.257                   
openai/text-embedding-ada-002                                   -0.029                  
pritamdeka/S-BioBert-snli-multinli-stsb                         0.086                   
pritamdeka/S-Biomed-Roberta-snli-multinli-stsb                  -0.257                  
pritamdeka/S-PubMedBert-MS-MARCO-SCIFACT                        0.543                   
sentence-transformers/all-MiniLM-L6-v2                          0.029                   
sentence-transformers/all-mpnet-base-v2                         0.143                   
sentence-transformers/all-roberta-large-v1                      -0.029                  
sentence-transformers/average_word_embeddings_glove.6B.300d     0.486                   
sentence-transformers/average_word_embeddings_glove.840B.300d   0.543                   
sentence-transformers/msmarco-distilbert-base-v3                -0.257                  
sentence-transformers/paraphrase-TinyBERT-L6-v2                 -0.029                  
sentence-transformers/sentence-t5-large                         -0.371                  
sentence-transformers/sentence-t5-xl                            0.086                   
thenlper/gte-large                                              0.143                   
word_overlap                                                    -0.371                  
