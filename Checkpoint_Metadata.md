Checkpoint                                                       Embedding_Size  Data_Source_Type   Model_Category                                                   Fine_Tuning                                                                                                                                                                                               
--------------------------------------------------------------  ---------------  -----------------  ---------------------------------------------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
FremyCompany/BioLORD-2023                                                   768  Biomedical         Ontology-driven concept representations                          This model is based on sentence-transformers/all-mpnet-base-v2 and was further finetuned on the BioLORD-Dataset and LLM-generated definitions from the Automatic Glossary of Clinical Terminology (AGCT). 
NeuML/pubmedbert-base-embeddings                                            768  Biomedical         Bidirectional Encoder Representations from Transformers (BERT)   NA                                                                                                                                                                                                        
albert/albert-base-v2                                                       768  General            Masked language modeling (MLM)                                   NA                                                                                                                                                                                                        
albert/albert-xxlarge-v2                                                   4096  General            Masked language modeling (MLM)                                   This checkpoint ostentibly is a fine-tuning of albert/albert-xxlarge-v2.                                                                                                                                  
allenai/biomed_roberta_base                                                 768  Biomedical         Bidirectional Encoder Representations from Transformers (BERT)   NA                                                                                                                                                                                                        
allenai/scibert_scivocab_uncased                                            768  Scientific         Bidirectional Encoder Representations from Transformers (BERT)   NA                                                                                                                                                                                                        
emilyalsentzer/Bio_ClinicalBERT                                             768  Biomedical         Bidirectional Encoder Representations from Transformers (BERT)   NA                                                                                                                                                                                                        
fasttext/cbow-commoncrawl                                                   300  General            Continuous Bag of Words (Word2Vec)                               NA                                                                                                                                                                                                        
fasttext/cbow-wikinews                                                      300  General            Continuous Bag of Words (Word2Vec)                               NA                                                                                                                                                                                                        
hkunlp/instructor-xl                                                        768  General            Instruction-finetuned text embedding model                       NA                                                                                                                                                                                                        
medicalai/ClinicalBERT                                                      768  Biomedical         Bidirectional Encoder Representations from Transformers (BERT)   NA                                                                                                                                                                                                        
microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract-fulltext               768  Biomedical         Bidirectional Encoder Representations from Transformers (BERT)   NA                                                                                                                                                                                                        
nomic-ai/nomic-embed-text-v1.5                                              768  General            Matryoshka Representation Learning                               NA                                                                                                                                                                                                        
nuvocare/WikiMedical_sent_biobert                                           768  Biomedical         Bidirectional Encoder Representations from Transformers (BERT)   Based on the dmis-lab/biobert-base-cased-v1.2 backbone and has been trained on the WikiMedical_sentence_simialrity dataset.                                                                               
openai/text-embedding-3-large                                              3072  General            Generative Pre-trained Transformer (GPT)                         NA                                                                                                                                                                                                        
openai/text-embedding-3-small                                              1536  General            Generative Pre-trained Transformer (GPT)                         NA                                                                                                                                                                                                        
openai/text-embedding-ada-002                                              1536  General            Generative Pre-trained Transformer (GPT)                         NA                                                                                                                                                                                                        
pritamdeka/S-BioBert-snli-multinli-stsb                                     768  Biomedical         Bidirectional Encoder Representations from Transformers (BERT)   NA                                                                                                                                                                                                        
pritamdeka/S-Biomed-Roberta-snli-multinli-stsb                              768  Biomedical         Bidirectional Encoder Representations from Transformers (BERT)   The base model used is allenai/biomed_roberta_base which has been fine-tuned for sentence similarity.                                                                                                     
pritamdeka/S-PubMedBert-MS-MARCO-SCIFACT                                    768  Biomedical         Bidirectional Encoder Representations from Transformers (BERT)   NA                                                                                                                                                                                                        
sentence-transformers/all-MiniLM-L6-v2                                      384  General            Self-supervised contrastive learning                             We used the pretrained nreimers/MiniLM-L6-H384-uncased model and fine-tuned in on a 1B sentence pairs dataset.                                                                                            
sentence-transformers/all-mpnet-base-v2                                     768  General            Self-supervised contrastive learning                             We used the pretrained microsoft/mpnet-base model and fine-tuned in on a 1B sentence pairs dataset.                                                                                                       
sentence-transformers/all-roberta-large-v1                                 1024  General            Self-supervised contrastive learning                             We used the pretrained roberta-large model and fine-tuned in on a 1B sentence pairs dataset.                                                                                                              
sentence-transformers/average_word_embeddings_glove.6B.300d                 300  General            Global Vectors for Word Representation (GloVe)                   NA                                                                                                                                                                                                        
sentence-transformers/average_word_embeddings_glove.840B.300d               300  General            Global Vectors for Word Representation (GloVe)                   NA                                                                                                                                                                                                        
sentence-transformers/msmarco-distilbert-base-v3                            768  General            Bidirectional Encoder Representations from Transformers (BERT)   NA                                                                                                                                                                                                        
sentence-transformers/paraphrase-TinyBERT-L6-v2                             768  General            Bidirectional Encoder Representations from Transformers (BERT)   NA                                                                                                                                                                                                        
sentence-transformers/sentence-t5-large                                     768  General            Text-to-text transformers (T5)                                   NA                                                                                                                                                                                                        
sentence-transformers/sentence-t5-xl                                        768  General            Text-to-text transformers (T5)                                   NA                                                                                                                                                                                                        
thenlper/gte-large                                                         1024  General            General Text Embeddings (GTE)                                    NA                                                                                                                                                                                                        
